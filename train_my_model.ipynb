{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to do , I am using 2 different computational graphs, so need 2 different sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import six\n",
    "#import tensorflow as tf\n",
    "\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_postprocess\n",
    "import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes=4\n",
    "data_base_directory='data/datav2/'\n",
    "alphabet_dict={0:'A' , 1:'B' , 2:'C' , 3:'D' , 4:'E', 5:'F' , 6:'G' ,7 :'H' , 8:'I', 9:'J'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_function(input):\n",
    "  \n",
    "  \n",
    "\n",
    "  input=data_base_directory + str(input ,'utf-8')\n",
    "  #print(str(input,'utf-8'))\n",
    "\n",
    " \n",
    "\n",
    "  for i in range(num_classes):\n",
    "     if alphabet_dict[i] in input:\n",
    "         y=int(i)\n",
    "\n",
    "  #if 'A' in str(input,'utf-8'):\n",
    "   #     y=0\n",
    " \n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "  return  input,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'data/datav2/20_48_00026A.wav']\n",
      "[b'data/datav2/20_48_00010A.wav']\n",
      "[b'data/datav2/20_50_46072A.wav']\n",
      "[b'data/datav2/20_50_46134A.wav']\n",
      "[b'data/datav2/20_54_21016B.wav']\n",
      "[b'data/datav2/20_50_46019A.wav']\n",
      "[b'data/datav2/20_48_00028A.wav']\n",
      "[b'data/datav2/20_50_46000A.wav']\n",
      "[b'data/datav2/20_50_46025A.wav']\n",
      "[b'data/datav2/20_50_46013A.wav']\n",
      "[b'data/datav2/20_50_46086A.wav']\n",
      "[b'data/datav2/20_54_21000B.wav']\n",
      "[b'data/datav2/20_54_21023B.wav']\n",
      "[b'data/datav2/20_50_46096A.wav']\n",
      "[b'data/datav2/20_50_46037A.wav']\n",
      "[b'data/datav2/20_54_21041B.wav']\n",
      "[b'data/datav2/20_50_46065A.wav']\n",
      "[b'data/datav2/20_50_46069A.wav']\n",
      "[b'data/datav2/20_50_46116A.wav']\n",
      "[b'data/datav2/20_50_46055A.wav']\n",
      "[b'data/datav2/20_56_39001B.wav']\n",
      "[b'data/datav2/20_50_46053A.wav']\n",
      "[b'data/datav2/20_50_46127A.wav']\n",
      "[b'data/datav2/20_50_46007A.wav']\n",
      "[b'data/datav2/20_50_46051A.wav']\n",
      "[b'data/datav2/20_54_21011B.wav']\n",
      "[b'data/datav2/20_54_21029B.wav']\n",
      "[b'data/datav2/20_50_46042A.wav']\n",
      "[b'data/datav2/20_50_46011A.wav']\n",
      "[b'data/datav2/20_50_46018A.wav']\n",
      "[b'data/datav2/20_54_21021B.wav']\n",
      "[b'data/datav2/20_50_46021A.wav']\n",
      "[b'data/datav2/20_54_21049B.wav']\n",
      "[b'data/datav2/20_50_46050A.wav']\n",
      "[b'data/datav2/20_50_46034A.wav']\n",
      "[b'data/datav2/20_50_46070A.wav']\n",
      "[b'data/datav2/20_48_00005A.wav']\n",
      "[b'data/datav2/20_50_46047A.wav']\n",
      "[b'data/datav2/20_50_46103A.wav']\n",
      "[b'data/datav2/20_50_46095A.wav']\n",
      "[b'data/datav2/20_50_46106A.wav']\n",
      "[b'data/datav2/20_54_21040B.wav']\n",
      "[b'data/datav2/20_56_39007B.wav']\n",
      "[b'data/datav2/20_54_21007B.wav']\n",
      "[b'data/datav2/20_54_21005B.wav']\n",
      "[b'data/datav2/20_48_00024A.wav']\n",
      "[b'data/datav2/20_50_46068A.wav']\n",
      "[b'data/datav2/20_50_46131A.wav']\n",
      "[b'data/datav2/20_50_46066A.wav']\n",
      "[b'data/datav2/20_50_46125A.wav']\n",
      "[b'data/datav2/20_54_21003B.wav']\n",
      "[b'data/datav2/20_54_21017B.wav']\n",
      "[b'data/datav2/20_56_39023B.wav']\n",
      "[b'data/datav2/20_50_46115A.wav']\n",
      "[b'data/datav2/20_54_21035B.wav']\n",
      "[b'data/datav2/20_50_46036A.wav']\n",
      "[b'data/datav2/20_56_39015B.wav']\n",
      "[b'data/datav2/20_50_46074A.wav']\n",
      "[b'data/datav2/20_48_00022A.wav']\n",
      "[b'data/datav2/20_56_39019B.wav']\n",
      "[b'data/datav2/20_56_39002B.wav']\n",
      "[b'data/datav2/20_50_46008A.wav']\n",
      "[b'data/datav2/20_56_39021B.wav']\n",
      "[b'data/datav2/20_54_21028B.wav']\n",
      "[b'data/datav2/20_56_39028B.wav']\n",
      "[b'data/datav2/20_50_46077A.wav']\n",
      "[b'data/datav2/20_56_39010B.wav']\n",
      "[b'data/datav2/20_58_52006C.wav']\n",
      "[b'data/datav2/20_50_46063A.wav']\n",
      "[b'data/datav2/20_50_46058A.wav']\n",
      "[b'data/datav2/20_50_46099A.wav']\n",
      "[b'data/datav2/20_54_21004B.wav']\n",
      "[b'data/datav2/20_54_21001B.wav']\n",
      "[b'data/datav2/20_50_46002A.wav']\n",
      "[b'data/datav2/20_58_52002C.wav']\n",
      "[b'data/datav2/20_56_39040B.wav']\n",
      "[b'data/datav2/20_54_21015B.wav']\n",
      "[b'data/datav2/20_50_46109A.wav']\n",
      "[b'data/datav2/20_50_46022A.wav']\n",
      "[b'data/datav2/20_50_46119A.wav']\n",
      "[b'data/datav2/20_50_46093A.wav']\n",
      "[b'data/datav2/20_50_46133A.wav']\n",
      "[b'data/datav2/20_50_46052A.wav']\n",
      "[b'data/datav2/20_56_39017B.wav']\n",
      "[b'data/datav2/20_50_46044A.wav']\n",
      "[b'data/datav2/20_50_46088A.wav']\n",
      "[b'data/datav2/20_56_39004B.wav']\n",
      "[b'data/datav2/20_54_21033B.wav']\n",
      "[b'data/datav2/20_58_52012C.wav']\n",
      "[b'data/datav2/20_56_39039B.wav']\n",
      "[b'data/datav2/20_58_52004C.wav']\n",
      "[b'data/datav2/20_50_46054A.wav']\n",
      "[b'data/datav2/20_48_00018A.wav']\n",
      "[b'data/datav2/20_48_00014A.wav']\n",
      "[b'data/datav2/20_58_52027C.wav']\n",
      "[b'data/datav2/20_48_00007A.wav']\n",
      "[b'data/datav2/20_58_52033C.wav']\n",
      "[b'data/datav2/20_50_46118A.wav']\n",
      "[b'data/datav2/20_50_46033A.wav']\n",
      "[b'data/datav2/20_50_46015A.wav']\n",
      "[b'data/datav2/20_50_46027A.wav']\n",
      "[b'data/datav2/20_50_46120A.wav']\n",
      "[b'data/datav2/20_56_39037B.wav']\n",
      "[b'data/datav2/20_48_00002A.wav']\n",
      "[b'data/datav2/20_50_46056A.wav']\n",
      "[b'data/datav2/20_54_21022B.wav']\n",
      "[b'data/datav2/20_48_00021A.wav']\n",
      "[b'data/datav2/20_50_46014A.wav']\n",
      "[b'data/datav2/20_58_52025C.wav']\n",
      "[b'data/datav2/20_56_39016B.wav']\n",
      "[b'data/datav2/20_54_21038B.wav']\n",
      "[b'data/datav2/20_50_46110A.wav']\n",
      "[b'data/datav2/20_56_39029B.wav']\n",
      "[b'data/datav2/20_58_52048C.wav']\n",
      "[b'data/datav2/20_50_46100A.wav']\n",
      "[b'data/datav2/20_50_46004A.wav']\n",
      "[b'data/datav2/20_58_52052C.wav']\n",
      "[b'data/datav2/20_50_46030A.wav']\n",
      "[b'data/datav2/20_50_46075A.wav']\n",
      "[b'data/datav2/20_50_46059A.wav']\n",
      "[b'data/datav2/20_48_00020A.wav']\n",
      "[b'data/datav2/20_56_39014B.wav']\n",
      "[b'data/datav2/20_54_21019B.wav']\n",
      "[b'data/datav2/20_48_00012A.wav']\n",
      "[b'data/datav2/20_54_21032B.wav']\n",
      "[b'data/datav2/20_50_46076A.wav']\n",
      "[b'data/datav2/20_58_52058C.wav']\n",
      "[b'data/datav2/20_50_46038A.wav']\n",
      "[b'data/datav2/20_58_52062C.wav']\n",
      "[b'data/datav2/20_50_46098A.wav']\n",
      "[b'data/datav2/20_50_46001A.wav']\n",
      "[b'data/datav2/20_54_21025B.wav']\n",
      "[b'data/datav2/20_54_21044B.wav']\n",
      "[b'data/datav2/20_58_52034C.wav']\n",
      "[b'data/datav2/20_50_46105A.wav']\n",
      "[b'data/datav2/20_48_00003A.wav']\n",
      "[b'data/datav2/20_58_52026C.wav']\n",
      "[b'data/datav2/20_58_52072C.wav']\n",
      "[b'data/datav2/20_58_52035C.wav']\n",
      "[b'data/datav2/20_56_39034B.wav']\n",
      "[b'data/datav2/20_50_46041A.wav']\n",
      "[b'data/datav2/20_54_21027B.wav']\n",
      "[b'data/datav2/20_58_52000C.wav']\n",
      "[b'data/datav2/20_50_46081A.wav']\n",
      "[b'data/datav2/20_50_46060A.wav']\n",
      "[b'data/datav2/20_50_46087A.wav']\n",
      "[b'data/datav2/20_50_46107A.wav']\n",
      "[b'data/datav2/20_58_52007C.wav']\n",
      "[b'data/datav2/20_58_52039C.wav']\n",
      "[b'data/datav2/20_56_39000B.wav']\n",
      "[b'data/datav2/20_50_46092A.wav']\n",
      "[b'data/datav2/20_50_46097A.wav']\n",
      "[b'data/datav2/20_56_39032B.wav']\n",
      "[b'data/datav2/20_50_46028A.wav']\n",
      "[b'data/datav2/20_54_21009B.wav']\n",
      "[b'data/datav2/20_58_52079C.wav']\n",
      "[b'data/datav2/20_54_21031B.wav']\n",
      "[b'data/datav2/20_54_21042B.wav']\n",
      "[b'data/datav2/20_54_21043B.wav']\n",
      "[b'data/datav2/20_48_00027A.wav']\n",
      "[b'data/datav2/20_58_52010C.wav']\n",
      "[b'data/datav2/20_58_52083C.wav']\n",
      "[b'data/datav2/20_48_00013A.wav']\n",
      "[b'data/datav2/20_50_46009A.wav']\n",
      "[b'data/datav2/20_54_21047B.wav']\n",
      "[b'data/datav2/20_58_52097C.wav']\n",
      "[b'data/datav2/20_58_52021C.wav']\n",
      "[b'data/datav2/20_50_46010A.wav']\n",
      "[b'data/datav2/20_54_21039B.wav']\n",
      "[b'data/datav2/20_50_46089A.wav']\n",
      "[b'data/datav2/20_58_52022C.wav']\n",
      "[b'data/datav2/20_58_52063C.wav']\n",
      "[b'data/datav2/20_58_52078C.wav']\n",
      "[b'data/datav2/20_58_52086C.wav']\n",
      "[b'data/datav2/20_58_52081C.wav']\n",
      "[b'data/datav2/20_58_52053C.wav']\n",
      "[b'data/datav2/20_58_52043C.wav']\n",
      "[b'data/datav2/20_58_52110C.wav']\n",
      "[b'data/datav2/20_58_52055C.wav']\n",
      "[b'data/datav2/20_58_52096C.wav']\n",
      "[b'data/datav2/20_50_46040A.wav']\n",
      "[b'data/datav2/20_58_52073C.wav']\n",
      "[b'data/datav2/20_58_52059C.wav']\n",
      "[b'data/datav2/20_58_52071C.wav']\n",
      "[b'data/datav2/20_58_52100C.wav']\n",
      "[b'data/datav2/20_56_39022B.wav']\n",
      "[b'data/datav2/20_58_52040C.wav']\n",
      "[b'data/datav2/20_58_52095C.wav']\n",
      "[b'data/datav2/20_50_46082A.wav']\n",
      "[b'data/datav2/20_56_39031B.wav']\n",
      "[b'data/datav2/20_50_46122A.wav']\n",
      "[b'data/datav2/20_54_21046B.wav']\n",
      "[b'data/datav2/20_54_21014B.wav']\n",
      "[b'data/datav2/20_58_52114C.wav']\n",
      "[b'data/datav2/20_58_52112C.wav']\n",
      "[b'data/datav2/20_58_52023C.wav']\n",
      "[b'data/datav2/20_58_52085C.wav']\n",
      "[b'data/datav2/20_58_52014C.wav']\n",
      "[b'data/datav2/20_50_46032A.wav']\n",
      "[b'data/datav2/20_58_52064C.wav']\n"
     ]
    }
   ],
   "source": [
    "logfilepath='data/dataset.txt'\n",
    "dataset = tf.data.TextLineDataset(logfilepath).shuffle(buffer_size=200) #.map(map_function)\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda filename: tuple(tf.py_func(\n",
    "        process_function, [filename],  [tf.string,tf.int64])))\n",
    "\n",
    "dataset=dataset.batch(1)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    for i in range(200):\n",
    "      value = sess.run(next_element[0])\n",
    "      print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "num_steps = 500\n",
    "batch_size = 2\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 128 # MNIST data input (img shape: 28*28)\n",
    "#num_classes = 5 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.int32, [None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 =  tf.nn.elu (tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 =  tf.nn.elu(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "Logits = neural_net(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "#loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    " #   logits=logits, labels=Y))\n",
    "prediction = tf.nn.softmax(Logits)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=Logits))\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(Logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/datav2/20_50_46038A.wav\n",
      "[[[-1.12978737 -0.484816   -0.50931633 ... -2.55864364 -2.56120469\n",
      "   -2.73118087]\n",
      "  [-0.32528157 -1.18447556 -0.18761478 ... -3.54096869 -3.47272872\n",
      "   -3.62046983]\n",
      "  [-1.12022411 -0.55269468 -0.20893125 ... -3.7981272  -3.71390192\n",
      "   -3.70605061]\n",
      "  ...\n",
      "  [-1.10347048 -1.24851905  0.68397672 ... -2.99936885 -3.06113702\n",
      "   -3.96019784]\n",
      "  [-1.41108985 -0.98967099  0.66131641 ... -3.38197333 -3.37824862\n",
      "   -3.51605169]\n",
      "  [-2.14763618 -1.58263743  0.7749115  ... -3.68581035 -3.56579007\n",
      "   -3.66093811]]\n",
      "\n",
      " [[-1.93383517 -1.5147824   0.64292248 ... -3.79676084 -3.66523049\n",
      "   -3.8893739 ]\n",
      "  [-1.55679351 -1.58949676  0.81459531 ... -3.83428883 -3.42111123\n",
      "   -3.60055281]\n",
      "  [-0.89059472 -2.02527303  0.95151461 ... -3.93778216 -3.69208625\n",
      "   -3.74298804]\n",
      "  ...\n",
      "  [-0.96371902 -1.12399775  0.18110006 ... -3.3748769  -2.9571567\n",
      "   -2.973651  ]\n",
      "  [-1.99817251 -0.66230004  0.23193735 ... -3.39231654 -3.06285541\n",
      "   -2.90667629]\n",
      "  [-1.36999589 -0.86164656  0.18305598 ... -3.59034458 -2.9959434\n",
      "   -3.08965378]]\n",
      "\n",
      " [[-0.66279211  0.04184431  0.1198403  ... -3.62128215 -3.29365041\n",
      "   -3.49883945]\n",
      "  [-0.92898458  0.0924967   0.0220688  ... -3.53644095 -3.17878372\n",
      "   -3.50256404]\n",
      "  [-0.1901973   0.63653921  0.76645062 ... -3.94596217 -3.47671517\n",
      "   -3.63503238]\n",
      "  ...\n",
      "  [-3.46510578 -3.05072715 -3.68584994 ... -3.69813979 -3.3041387\n",
      "   -2.9171553 ]\n",
      "  [-3.80211251 -2.78152165 -2.63268649 ... -3.42825496 -3.20597556\n",
      "   -3.27702417]\n",
      "  [-2.86552315 -2.88824328 -4.0062401  ... -3.3875134  -3.4096196\n",
      "   -3.25993441]]]\n",
      "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n",
      "[[0.         0.         0.         0.         0.03249924 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.37132585 0.         0.0429827  0.20243785 0.07353982\n",
      "  0.         0.         0.         0.         0.11737654 0.\n",
      "  0.07279405 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.18949386 0.         0.\n",
      "  0.1253617  0.6354737  0.         0.         0.08997542 0.\n",
      "  0.9199901  0.08916572 0.         0.         1.5424594  0.08284301\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.43177715 0.         0.80426806 0.         0.         0.5055136\n",
      "  0.14200348 0.         0.42803624 0.         0.         0.\n",
      "  0.51743066 0.10755632 0.         0.2538124  0.20521463 0.\n",
      "  0.         0.         0.         0.08327922 0.         0.53780276\n",
      "  0.         0.         0.         0.7475563  0.         0.\n",
      "  0.72928655 0.38108915 0.29820707 0.         0.         0.07334322\n",
      "  0.         0.         0.         0.3580318  0.         0.7276762\n",
      "  0.         0.3333442  0.         0.         0.         0.09883863\n",
      "  0.         0.         0.         0.         0.7661476  0.\n",
      "  0.5410606  0.         0.         0.         0.         0.3129483\n",
      "  0.         0.         0.         0.06077907 0.         0.62637657\n",
      "  0.29636443 0.18942553 0.         0.9618626  0.         0.\n",
      "  0.         0.        ]\n",
      " [0.05257145 0.         0.08202939 0.         0.13079724 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.44816604 0.15635055 0.         0.5734594  0.64635956\n",
      "  0.         0.04867068 0.17287518 0.         0.         0.\n",
      "  0.07006624 0.2322346  0.23210436 0.         0.         0.\n",
      "  0.         0.08800098 0.00972706 0.71283096 0.3672924  0.02214444\n",
      "  0.         0.         0.         0.18606642 0.6800258  0.\n",
      "  0.20921801 0.         0.         0.00896852 0.66148114 0.34545282\n",
      "  0.         0.02071989 0.2711037  0.         0.         0.\n",
      "  0.3571993  0.         0.38066888 0.         0.31645685 0.15125969\n",
      "  0.2243456  0.14907768 0.         0.         0.         0.\n",
      "  0.         0.21357477 0.07651087 0.11022615 0.29201818 0.09337349\n",
      "  0.         0.         0.         0.2825387  0.         0.5463362\n",
      "  0.34603152 0.         0.09483064 0.6149343  0.         0.\n",
      "  0.12820145 0.6694905  0.18118806 0.         0.         0.\n",
      "  0.         0.22035116 0.027428   0.31862876 0.         0.47004974\n",
      "  0.         0.         0.         0.13991158 0.         0.277616\n",
      "  0.05595555 0.16019093 0.         0.         0.27525055 0.\n",
      "  0.35665512 0.         0.         0.         0.         0.09136372\n",
      "  0.         0.         0.         0.         0.         0.34021938\n",
      "  0.6124584  0.12585464 0.09447885 0.29100922 0.         0.\n",
      "  0.         0.        ]\n",
      " [0.0784288  0.02468404 0.38066027 0.         0.054121   0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.01605672 0.         0.         0.0517211  0.8661668\n",
      "  0.         0.18353926 0.28081834 0.         0.         0.\n",
      "  0.31695285 0.         0.33763483 0.         0.         0.\n",
      "  0.         0.         0.04455936 1.1817071  0.6876155  0.\n",
      "  0.         0.         0.         0.         0.8423828  0.\n",
      "  0.3626767  0.         0.         0.0150643  0.28996736 0.\n",
      "  0.         0.03783199 0.         0.         0.6284253  0.\n",
      "  0.29051787 0.         0.3142381  0.         0.8027191  0.6141685\n",
      "  0.49333674 0.19341639 0.         0.         0.         0.\n",
      "  0.         0.11144882 0.         0.20936367 0.20793194 0.3504483\n",
      "  0.         0.33730552 0.         0.         0.         0.322491\n",
      "  0.28309375 0.0162648  0.186631   0.3562383  0.         0.\n",
      "  0.00550422 0.24222156 0.         0.         0.         0.\n",
      "  0.         0.24357083 0.12482502 0.         0.         0.13717222\n",
      "  0.         0.         0.         0.8316892  0.         0.04564199\n",
      "  0.44524056 0.55097055 0.         0.         0.11598974 0.\n",
      "  0.08015862 0.         0.         0.         0.19785422 0.\n",
      "  0.         0.         0.         0.         0.         0.03856666\n",
      "  0.993521   0.         0.14822343 0.45450968 0.         0.\n",
      "  0.         0.        ]]\n",
      "[[173  12 181  90 153  66  76 122 124 255  64   7 158 102  53   0  54  61\n",
      "  162 101  87 184 144   0 141 171 202 179 190 142 137 141 165 126  73 253\n",
      "  132 156 162  60 255  72  69 200  59 195  22 121   0 101 156 166 231 115\n",
      "  157 100 222 191 179 255 219 219  82 174 186 244 211  98 255 255  74  89\n",
      "  211 147 220 105  51 251 158 241 213 107 252 255 148  82  92 159  88 199\n",
      "  255 223  89 196 154 181  43  92  70  38 198   2  69 159   0 144 227  82\n",
      "  158 255 239 133  76 117 137  82 230   1   0  12 105 178  90   0 255  14\n",
      "  108 255]\n",
      " [165  15 161 120 194  72  96  81 177 196 114  45 152 157  55  49  77  89\n",
      "  188 133  64 183 119  24  99 165 172 219 185  62 105  53 143 102 134 122\n",
      "   86 147  71  90 111 110 128 168 209 117 109  90  19 214 208 172  88 100\n",
      "   73 120 168  96 160 170 142 117  27 217 117 137 140   0 204 230 109  50\n",
      "  207 204  26  49 119 170  37 242 131  91 243 215 203 137  20 196  81   0\n",
      "  136 255  65 170 105 238 117  24 225 136 204  96 120  82  58 243 167  82\n",
      "  163 171 153  36   0 166  80 106 214 205  19 121 105 100  95  37 251 112\n",
      "  145 255]\n",
      " [158   0 168 150 159  52  82  32 172 158 144  85 119 174   0  76  49  66\n",
      "  252  90  54 226 165  81  79 154  75 195 133  18 156  59 105 129 154 160\n",
      "  140  90 127  62   0  90 156 117 237 153 133  76  82 255 207 113 129  63\n",
      "  105  95 134  51 248 213  25  24   3 255 203 134 184  19 165  92  89 126\n",
      "  255 255   2   0  34 237   0 100 193 210 217  98 218 122 147 255 182 152\n",
      "   81 129  88  73  31 178 136   0 142 108 132 160 175 202  60 181 109   1\n",
      "  255 128 255 151   0 150 216 140 133 255   0 189 113 197   0   0 185 126\n",
      "  210 255]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f41d4975a8e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m               \u001b[0;31m# train single example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpostprocessed_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNext_element\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mNext_element\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(num_steps):\n",
    "        avg_cost = 0.\n",
    "        \n",
    "        \n",
    "        sess.run(iterator.initializer)\n",
    "        while True:\n",
    "            try:\n",
    "                Next_element=sess.run(next_element)\n",
    "                input_wav_file_name=str(Next_element[0][0],'utf-8')\n",
    "                print(input_wav_file_name)\n",
    "                \n",
    "                examples_batch = vggish_input.wavfile_to_examples(input_wav_file_name)\n",
    "                print(examples_batch)\n",
    "\n",
    "                # Prepare a postprocessor to munge the model embeddings.\n",
    "                pproc = vggish_postprocess.Postprocessor('vggish_pca_params.npz')\n",
    "                \n",
    "                vggish_slim.define_vggish_slim(training=False)\n",
    "                vggish_slim.load_vggish_slim_checkpoint(sess, 'vggish_model.ckpt')\n",
    "                features_tensor = sess.graph.get_tensor_by_name(\n",
    "                vggish_params.INPUT_TENSOR_NAME)\n",
    "                embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "                vggish_params.OUTPUT_TENSOR_NAME)\n",
    "\n",
    "    # Run inference and postprocessing.\n",
    "                [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                 feed_dict={features_tensor: examples_batch})\n",
    "                print(embedding_batch)\n",
    "                postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "                print(postprocessed_batch)\n",
    "    \n",
    "    \n",
    "\n",
    "              # train single example\n",
    "                _ , c = sess.run([optimizer, cost], feed_dict={x: postprocessed_batch,y: Next_element[1] , seq_len:Next_element[2]})\n",
    "            \n",
    "                 \n",
    "                print(c)\n",
    "                #print(pre)\n",
    "      #          print(p)\n",
    "               \n",
    "               \n",
    "              \n",
    "            except tf.errors.OutOfRangeError:\n",
    "              break\n",
    "   \n",
    "        \n",
    "                \n",
    "    # Save model weights to disk\n",
    "   # save_path = saver.save(sess, model_path)\n",
    "    #print(\"Model saved in file: %s\" % save_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

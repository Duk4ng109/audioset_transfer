{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to do , I am using 2 different computational graphs, so need 2 different sessions\n",
    "#[ done ] \n",
    "\n",
    "# use rnn to condense features into a single feature vector\n",
    "#  [ pending ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import six\n",
    "#import tensorflow as tf\n",
    "\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_postprocess\n",
    "import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes=4\n",
    "data_base_directory='data/datav2/'\n",
    "alphabet_dict={0:'A' , 1:'B' , 2:'C' , 3:'D' , 4:'E', 5:'F' , 6:'G' ,7 :'H' , 8:'I', 9:'J'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_function(input):\n",
    "  \n",
    "  \n",
    "\n",
    "  input=data_base_directory + str(input ,'utf-8')\n",
    "  #print(str(input,'utf-8'))\n",
    "\n",
    " \n",
    "\n",
    "  for i in range(num_classes):\n",
    "     if alphabet_dict[i] in input:\n",
    "         y=int(i)\n",
    "\n",
    "  #if 'A' in str(input,'utf-8'):\n",
    "   #     y=0\n",
    " \n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "  return  input,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'data/datav2/20_48_00018A.wav' b'data/datav2/20_50_46052A.wav'\n",
      " b'data/datav2/20_50_46120A.wav']\n",
      "[b'data/datav2/20_50_46093A.wav' b'data/datav2/20_50_46098A.wav'\n",
      " b'data/datav2/20_50_46054A.wav']\n",
      "[b'data/datav2/20_48_00006A.wav' b'data/datav2/20_48_00024A.wav'\n",
      " b'data/datav2/20_50_46032A.wav']\n",
      "[b'data/datav2/20_50_46056A.wav' b'data/datav2/20_54_21030B.wav'\n",
      " b'data/datav2/20_50_46105A.wav']\n",
      "[b'data/datav2/20_50_46116A.wav' b'data/datav2/20_50_46060A.wav'\n",
      " b'data/datav2/20_54_21039B.wav']\n",
      "[b'data/datav2/20_54_21050B.wav' b'data/datav2/20_54_21036B.wav'\n",
      " b'data/datav2/20_54_21001B.wav']\n",
      "[b'data/datav2/20_50_46085A.wav' b'data/datav2/20_48_00012A.wav'\n",
      " b'data/datav2/20_50_46040A.wav']\n",
      "[b'data/datav2/20_50_46096A.wav' b'data/datav2/20_50_46084A.wav'\n",
      " b'data/datav2/20_50_46066A.wav']\n",
      "[b'data/datav2/20_54_21012B.wav' b'data/datav2/20_50_46051A.wav'\n",
      " b'data/datav2/20_56_39006B.wav']\n",
      "[b'data/datav2/20_50_46068A.wav' b'data/datav2/20_48_00005A.wav'\n",
      " b'data/datav2/20_50_46043A.wav']\n",
      "[b'data/datav2/20_50_46046A.wav' b'data/datav2/20_50_46029A.wav'\n",
      " b'data/datav2/20_50_46012A.wav']\n",
      "[b'data/datav2/20_48_00016A.wav' b'data/datav2/20_54_21006B.wav'\n",
      " b'data/datav2/20_50_46072A.wav']\n",
      "[b'data/datav2/20_54_21002B.wav' b'data/datav2/20_50_46128A.wav'\n",
      " b'data/datav2/20_56_39021B.wav']\n",
      "[b'data/datav2/20_48_00022A.wav' b'data/datav2/20_56_39023B.wav'\n",
      " b'data/datav2/20_50_46048A.wav']\n",
      "[b'data/datav2/20_50_46042A.wav' b'data/datav2/20_50_46020A.wav'\n",
      " b'data/datav2/20_54_21021B.wav']\n",
      "[b'data/datav2/20_54_21047B.wav' b'data/datav2/20_56_39002B.wav'\n",
      " b'data/datav2/20_54_21015B.wav']\n",
      "[b'data/datav2/20_48_00023A.wav' b'data/datav2/20_50_46064A.wav'\n",
      " b'data/datav2/20_48_00009A.wav']\n",
      "[b'data/datav2/20_50_46033A.wav' b'data/datav2/20_50_46063A.wav'\n",
      " b'data/datav2/20_56_39033B.wav']\n",
      "[b'data/datav2/20_50_46114A.wav' b'data/datav2/20_48_00001A.wav'\n",
      " b'data/datav2/20_50_46089A.wav']\n",
      "[b'data/datav2/20_54_21044B.wav' b'data/datav2/20_56_39015B.wav'\n",
      " b'data/datav2/20_50_46016A.wav']\n",
      "[b'data/datav2/20_54_21025B.wav' b'data/datav2/20_50_46081A.wav'\n",
      " b'data/datav2/20_58_52000C.wav']\n",
      "[b'data/datav2/20_56_39019B.wav' b'data/datav2/20_50_46134A.wav'\n",
      " b'data/datav2/20_50_46079A.wav']\n",
      "[b'data/datav2/20_56_39001B.wav' b'data/datav2/20_48_00014A.wav'\n",
      " b'data/datav2/20_48_00015A.wav']\n",
      "[b'data/datav2/20_50_46108A.wav' b'data/datav2/20_50_46058A.wav'\n",
      " b'data/datav2/20_48_00027A.wav']\n",
      "[b'data/datav2/20_54_21049B.wav' b'data/datav2/20_54_21022B.wav'\n",
      " b'data/datav2/20_50_46005A.wav']\n",
      "[b'data/datav2/20_50_46026A.wav' b'data/datav2/20_48_00004A.wav'\n",
      " b'data/datav2/20_50_46083A.wav']\n",
      "[b'data/datav2/20_50_46003A.wav' b'data/datav2/20_48_00013A.wav'\n",
      " b'data/datav2/20_56_39012B.wav']\n",
      "[b'data/datav2/20_48_00000A.wav' b'data/datav2/20_54_21031B.wav'\n",
      " b'data/datav2/20_58_52012C.wav']\n",
      "[b'data/datav2/20_48_00008A.wav' b'data/datav2/20_50_46091A.wav'\n",
      " b'data/datav2/20_54_21013B.wav']\n",
      "[b'data/datav2/20_54_21029B.wav' b'data/datav2/20_50_46000A.wav'\n",
      " b'data/datav2/20_50_46075A.wav']\n",
      "[b'data/datav2/20_48_00025A.wav' b'data/datav2/20_50_46006A.wav'\n",
      " b'data/datav2/20_58_52031C.wav']\n",
      "[b'data/datav2/20_50_46019A.wav' b'data/datav2/20_56_39026B.wav'\n",
      " b'data/datav2/20_50_46065A.wav']\n",
      "[b'data/datav2/20_56_39020B.wav' b'data/datav2/20_50_46007A.wav'\n",
      " b'data/datav2/20_50_46011A.wav']\n",
      "[b'data/datav2/20_54_21040B.wav' b'data/datav2/20_50_46099A.wav'\n",
      " b'data/datav2/20_54_21027B.wav']\n",
      "[b'data/datav2/20_50_46002A.wav' b'data/datav2/20_54_21011B.wav'\n",
      " b'data/datav2/20_58_52005C.wav']\n",
      "[b'data/datav2/20_56_39022B.wav' b'data/datav2/20_58_52025C.wav'\n",
      " b'data/datav2/20_50_46035A.wav']\n",
      "[b'data/datav2/20_50_46009A.wav' b'data/datav2/20_54_21042B.wav'\n",
      " b'data/datav2/20_50_46059A.wav']\n",
      "[b'data/datav2/20_50_46013A.wav' b'data/datav2/20_58_52044C.wav'\n",
      " b'data/datav2/20_54_21038B.wav']\n",
      "[b'data/datav2/20_50_46112A.wav' b'data/datav2/20_50_46071A.wav'\n",
      " b'data/datav2/20_50_46044A.wav']\n",
      "[b'data/datav2/20_50_46115A.wav' b'data/datav2/20_50_46061A.wav'\n",
      " b'data/datav2/20_50_46053A.wav']\n",
      "[b'data/datav2/20_50_46104A.wav' b'data/datav2/20_50_46123A.wav'\n",
      " b'data/datav2/20_58_52024C.wav']\n",
      "[b'data/datav2/20_54_21004B.wav' b'data/datav2/20_48_00011A.wav'\n",
      " b'data/datav2/20_56_39039B.wav']\n",
      "[b'data/datav2/20_58_52067C.wav' b'data/datav2/20_56_39008B.wav'\n",
      " b'data/datav2/20_56_39005B.wav']\n",
      "[b'data/datav2/20_50_46095A.wav' b'data/datav2/20_50_46039A.wav'\n",
      " b'data/datav2/20_48_00028A.wav']\n",
      "[b'data/datav2/20_54_21043B.wav' b'data/datav2/20_50_46131A.wav'\n",
      " b'data/datav2/20_54_21016B.wav']\n",
      "[b'data/datav2/20_54_21007B.wav' b'data/datav2/20_58_52036C.wav'\n",
      " b'data/datav2/20_58_52072C.wav']\n",
      "[b'data/datav2/20_58_52041C.wav' b'data/datav2/20_54_21018B.wav'\n",
      " b'data/datav2/20_50_46004A.wav']\n",
      "[b'data/datav2/20_58_52011C.wav' b'data/datav2/20_50_46027A.wav'\n",
      " b'data/datav2/20_50_46086A.wav']\n",
      "[b'data/datav2/20_58_52059C.wav' b'data/datav2/20_50_46069A.wav'\n",
      " b'data/datav2/20_50_46017A.wav']\n",
      "[b'data/datav2/20_58_52014C.wav' b'data/datav2/20_58_52018C.wav'\n",
      " b'data/datav2/20_58_52006C.wav']\n",
      "[b'data/datav2/20_58_52040C.wav' b'data/datav2/20_58_52078C.wav'\n",
      " b'data/datav2/20_58_52069C.wav']\n",
      "[b'data/datav2/20_54_21009B.wav' b'data/datav2/20_58_52037C.wav'\n",
      " b'data/datav2/20_48_00026A.wav']\n",
      "[b'data/datav2/20_54_21032B.wav' b'data/datav2/20_56_39013B.wav'\n",
      " b'data/datav2/20_50_46022A.wav']\n",
      "[b'data/datav2/20_56_39030B.wav' b'data/datav2/20_48_00019A.wav'\n",
      " b'data/datav2/20_58_52057C.wav']\n",
      "[b'data/datav2/20_58_52083C.wav' b'data/datav2/20_50_46045A.wav'\n",
      " b'data/datav2/20_50_46049A.wav']\n",
      "[b'data/datav2/20_50_46103A.wav' b'data/datav2/20_50_46050A.wav'\n",
      " b'data/datav2/20_54_21026B.wav']\n",
      "[b'data/datav2/20_58_52038C.wav' b'data/datav2/20_58_52019C.wav'\n",
      " b'data/datav2/20_58_52088C.wav']\n",
      "[b'data/datav2/20_58_52001C.wav' b'data/datav2/20_54_21017B.wav'\n",
      " b'data/datav2/20_58_52033C.wav']\n",
      "[b'data/datav2/20_50_46010A.wav' b'data/datav2/20_50_46090A.wav'\n",
      " b'data/datav2/20_56_39031B.wav']\n",
      "[b'data/datav2/20_50_46076A.wav' b'data/datav2/20_58_52119C.wav'\n",
      " b'data/datav2/20_58_52002C.wav']\n",
      "[b'data/datav2/20_50_46077A.wav' b'data/datav2/20_58_52068C.wav'\n",
      " b'data/datav2/20_50_46036A.wav']\n",
      "[b'data/datav2/20_54_21048B.wav' b'data/datav2/20_54_21028B.wav'\n",
      " b'data/datav2/20_58_52097C.wav']\n",
      "[b'data/datav2/20_50_46074A.wav' b'data/datav2/20_58_52074C.wav'\n",
      " b'data/datav2/20_58_52094C.wav']\n",
      "[b'data/datav2/20_50_46129A.wav' b'data/datav2/20_54_21035B.wav'\n",
      " b'data/datav2/20_50_46113A.wav']\n",
      "[b'data/datav2/20_58_52112C.wav' b'data/datav2/20_50_46080A.wav'\n",
      " b'data/datav2/20_56_39035B.wav']\n",
      "[b'data/datav2/20_58_52114C.wav' b'data/datav2/20_50_46092A.wav'\n",
      " b'data/datav2/20_50_46109A.wav']\n",
      "[b'data/datav2/20_50_46117A.wav' b'data/datav2/20_58_52056C.wav'\n",
      " b'data/datav2/20_58_52008C.wav']\n",
      "[b'data/datav2/20_58_52135C.wav' b'data/datav2/20_58_52138C.wav'\n",
      " b'data/datav2/20_54_21033B.wav']\n",
      "[b'data/datav2/20_58_52020C.wav' b'data/datav2/20_50_46041A.wav'\n",
      " b'data/datav2/20_56_39003B.wav']\n",
      "[b'data/datav2/20_58_52111C.wav' b'data/datav2/20_50_46038A.wav'\n",
      " b'data/datav2/20_56_39032B.wav']\n",
      "[b'data/datav2/20_58_52141C.wav' b'data/datav2/20_58_52118C.wav'\n",
      " b'data/datav2/20_56_39025B.wav']\n",
      "[b'data/datav2/20_50_46055A.wav' b'data/datav2/20_50_46133A.wav'\n",
      " b'data/datav2/20_58_52103C.wav']\n",
      "[b'data/datav2/20_58_52039C.wav' b'data/datav2/20_50_46024A.wav'\n",
      " b'data/datav2/20_50_46101A.wav']\n",
      "[b'data/datav2/20_58_52035C.wav' b'data/datav2/20_56_39038B.wav'\n",
      " b'data/datav2/20_58_52061C.wav']\n",
      "[b'data/datav2/20_50_46132A.wav' b'data/datav2/20_58_52136C.wav'\n",
      " b'data/datav2/20_58_52070C.wav']\n",
      "[b'data/datav2/20_54_21020B.wav' b'data/datav2/20_50_46121A.wav'\n",
      " b'data/datav2/20_50_46008A.wav']\n",
      "[b'data/datav2/20_50_46107A.wav' b'data/datav2/20_54_21037B.wav'\n",
      " b'data/datav2/20_50_46126A.wav']\n",
      "[b'data/datav2/20_58_52163C.wav' b'data/datav2/20_50_46047A.wav'\n",
      " b'data/datav2/20_58_52060C.wav']\n",
      "[b'data/datav2/20_54_21014B.wav' b'data/datav2/20_58_52075C.wav'\n",
      " b'data/datav2/20_50_46124A.wav']\n",
      "[b'data/datav2/20_58_52017C.wav' b'data/datav2/20_58_52054C.wav'\n",
      " b'data/datav2/20_48_00007A.wav']\n",
      "[b'data/datav2/20_56_39004B.wav' b'data/datav2/20_58_52125C.wav'\n",
      " b'data/datav2/20_58_52026C.wav']\n",
      "[b'data/datav2/20_58_52071C.wav' b'data/datav2/20_58_52120C.wav'\n",
      " b'data/datav2/20_58_52151C.wav']\n",
      "[b'data/datav2/20_50_46087A.wav' b'data/datav2/20_58_52150C.wav'\n",
      " b'data/datav2/20_58_52055C.wav']\n",
      "[b'data/datav2/20_58_52172C.wav' b'data/datav2/20_58_52155C.wav'\n",
      " b'data/datav2/20_50_46023A.wav']\n",
      "[b'data/datav2/20_50_46130A.wav' b'data/datav2/20_50_46028A.wav'\n",
      " b'data/datav2/20_50_46122A.wav']\n",
      "[b'data/datav2/20_58_52130C.wav' b'data/datav2/20_58_52129C.wav'\n",
      " b'data/datav2/20_58_52126C.wav']\n",
      "[b'data/datav2/20_58_52099C.wav' b'data/datav2/20_58_52175C.wav'\n",
      " b'data/datav2/20_50_46110A.wav']\n",
      "[b'data/datav2/20_56_39000B.wav' b'data/datav2/20_50_46119A.wav'\n",
      " b'data/datav2/20_50_46125A.wav']\n",
      "[b'data/datav2/20_58_52168C.wav' b'data/datav2/20_58_52089C.wav'\n",
      " b'data/datav2/20_58_52021C.wav']\n",
      "[b'data/datav2/20_58_52122C.wav' b'data/datav2/20_58_52179C.wav'\n",
      " b'data/datav2/20_58_52079C.wav']\n",
      "[b'data/datav2/20_58_52106C.wav' b'data/datav2/20_58_52096C.wav'\n",
      " b'data/datav2/20_54_21008B.wav']\n",
      "[b'data/datav2/20_58_52153C.wav' b'data/datav2/20_58_52131C.wav'\n",
      " b'data/datav2/20_54_21046B.wav']\n",
      "[b'data/datav2/20_58_52187C.wav' b'data/datav2/20_58_52139C.wav'\n",
      " b'data/datav2/20_58_52160C.wav']\n",
      "[b'data/datav2/20_50_46025A.wav' b'data/datav2/20_58_52171C.wav'\n",
      " b'data/datav2/20_58_52202C.wav']\n",
      "[b'data/datav2/20_58_52063C.wav' b'data/datav2/20_58_52181C.wav'\n",
      " b'data/datav2/20_58_52146C.wav']\n",
      "[b'data/datav2/20_58_52183C.wav' b'data/datav2/20_58_52204C.wav'\n",
      " b'data/datav2/20_58_52053C.wav']\n",
      "[b'data/datav2/20_50_46015A.wav' b'data/datav2/20_58_52213C.wav'\n",
      " b'data/datav2/20_58_52229C.wav']\n",
      "[b'data/datav2/20_58_52123C.wav' b'data/datav2/20_58_52196C.wav'\n",
      " b'data/datav2/20_58_52142C.wav']\n",
      "[b'data/datav2/20_58_52211C.wav' b'data/datav2/20_58_52115C.wav'\n",
      " b'data/datav2/20_58_52137C.wav']\n",
      "[b'data/datav2/20_50_46094A.wav' b'data/datav2/20_58_52178C.wav'\n",
      " b'data/datav2/20_58_52188C.wav']\n",
      "[b'data/datav2/20_56_39011B.wav' b'data/datav2/20_58_52170C.wav'\n",
      " b'data/datav2/20_58_52090C.wav']\n",
      "[b'data/datav2/20_54_21034B.wav' b'data/datav2/20_58_52205C.wav'\n",
      " b'data/datav2/20_58_52013C.wav']\n",
      "[b'data/datav2/20_58_52101C.wav' b'data/datav2/20_58_52032C.wav'\n",
      " b'data/datav2/20_54_21024B.wav']\n",
      "[b'data/datav2/20_58_52191C.wav' b'data/datav2/20_58_52220C.wav'\n",
      " b'data/datav2/20_50_46067A.wav']\n",
      "[b'data/datav2/20_56_39009B.wav' b'data/datav2/20_58_52081C.wav'\n",
      " b'data/datav2/20_58_52023C.wav']\n",
      "[b'data/datav2/20_58_52147C.wav' b'data/datav2/20_56_39024B.wav'\n",
      " b'data/datav2/20_58_52016C.wav']\n",
      "[b'data/datav2/20_54_21019B.wav' b'data/datav2/20_58_52022C.wav'\n",
      " b'data/datav2/20_58_52189C.wav']\n",
      "[b'data/datav2/20_58_52184C.wav' b'data/datav2/20_58_52199C.wav'\n",
      " b'data/datav2/20_58_52180C.wav']\n",
      "[b'data/datav2/20_50_46097A.wav' b'data/datav2/20_50_46111A.wav'\n",
      " b'data/datav2/20_56_39041B.wav']\n",
      "[b'data/datav2/20_58_52156C.wav' b'data/datav2/20_50_46062A.wav'\n",
      " b'data/datav2/20_50_46118A.wav']\n",
      "[b'data/datav2/20_58_52113C.wav' b'data/datav2/20_58_52042C.wav'\n",
      " b'data/datav2/20_50_46088A.wav']\n",
      "[b'data/datav2/21_03_20013D.wav' b'data/datav2/20_58_52091C.wav'\n",
      " b'data/datav2/20_58_52128C.wav']\n",
      "[b'data/datav2/21_03_20010D.wav' b'data/datav2/20_58_52007C.wav'\n",
      " b'data/datav2/20_56_39028B.wav']\n",
      "[b'data/datav2/21_02_39025D.wav' b'data/datav2/20_58_52082C.wav'\n",
      " b'data/datav2/20_50_46106A.wav']\n",
      "[b'data/datav2/20_58_52212C.wav' b'data/datav2/20_48_00020A.wav'\n",
      " b'data/datav2/20_58_52159C.wav']\n",
      "[b'data/datav2/20_56_39029B.wav' b'data/datav2/20_58_52085C.wav'\n",
      " b'data/datav2/20_54_21003B.wav']\n",
      "[b'data/datav2/21_03_20014D.wav' b'data/datav2/20_58_52066C.wav'\n",
      " b'data/datav2/20_58_52077C.wav']\n",
      "[b'data/datav2/21_02_39006D.wav' b'data/datav2/21_02_39020D.wav'\n",
      " b'data/datav2/20_58_52004C.wav']\n",
      "[b'data/datav2/20_58_52149C.wav' b'data/datav2/20_58_52227C.wav'\n",
      " b'data/datav2/20_50_46030A.wav']\n",
      "[b'data/datav2/20_58_52218C.wav' b'data/datav2/20_58_52046C.wav'\n",
      " b'data/datav2/21_08_08002D.wav']\n",
      "[b'data/datav2/20_58_52134C.wav' b'data/datav2/20_58_52110C.wav'\n",
      " b'data/datav2/20_50_46127A.wav']\n",
      "[b'data/datav2/20_58_52093C.wav' b'data/datav2/20_58_52045C.wav'\n",
      " b'data/datav2/20_58_52117C.wav']\n",
      "[b'data/datav2/20_58_52095C.wav' b'data/datav2/20_58_52043C.wav'\n",
      " b'data/datav2/20_56_39036B.wav']\n",
      "[b'data/datav2/20_58_52221C.wav' b'data/datav2/20_56_39010B.wav'\n",
      " b'data/datav2/21_08_08007D.wav']\n",
      "[b'data/datav2/20_58_52028C.wav' b'data/datav2/20_58_52105C.wav'\n",
      " b'data/datav2/20_58_52050C.wav']\n",
      "[b'data/datav2/21_03_20008D.wav' b'data/datav2/20_56_39027B.wav'\n",
      " b'data/datav2/20_56_39016B.wav']\n",
      "[b'data/datav2/20_50_46082A.wav' b'data/datav2/20_50_46014A.wav'\n",
      " b'data/datav2/20_58_52049C.wav']\n",
      "[b'data/datav2/20_58_52233C.wav' b'data/datav2/20_58_52201C.wav'\n",
      " b'data/datav2/20_58_52145C.wav']\n",
      "[b'data/datav2/20_58_52109C.wav' b'data/datav2/20_50_46031A.wav'\n",
      " b'data/datav2/20_58_52186C.wav']\n",
      "[b'data/datav2/20_58_52216C.wav' b'data/datav2/20_58_52157C.wav'\n",
      " b'data/datav2/20_58_52073C.wav']\n",
      "[b'data/datav2/20_58_52029C.wav' b'data/datav2/20_58_52192C.wav'\n",
      " b'data/datav2/20_58_52158C.wav']\n",
      "[b'data/datav2/20_58_52209C.wav' b'data/datav2/21_08_08001D.wav'\n",
      " b'data/datav2/20_58_52048C.wav']\n",
      "[b'data/datav2/20_56_39042B.wav' b'data/datav2/21_08_08012D.wav'\n",
      " b'data/datav2/21_08_08006D.wav']\n",
      "[b'data/datav2/20_48_00003A.wav' b'data/datav2/21_02_39026D.wav'\n",
      " b'data/datav2/20_58_52027C.wav']\n",
      "[b'data/datav2/20_58_52132C.wav' b'data/datav2/20_56_39007B.wav'\n",
      " b'data/datav2/21_02_39004D.wav']\n",
      "[b'data/datav2/21_08_08003D.wav' b'data/datav2/21_02_39011D.wav'\n",
      " b'data/datav2/20_58_52140C.wav']\n",
      "[b'data/datav2/20_58_52065C.wav' b'data/datav2/20_48_00017A.wav'\n",
      " b'data/datav2/21_02_39010D.wav']\n",
      "[b'data/datav2/21_02_39015D.wav' b'data/datav2/20_58_52195C.wav'\n",
      " b'data/datav2/20_58_52228C.wav']\n",
      "[b'data/datav2/20_50_46018A.wav' b'data/datav2/21_03_20009D.wav'\n",
      " b'data/datav2/20_58_52177C.wav']\n",
      "[b'data/datav2/20_58_52003C.wav' b'data/datav2/20_50_46037A.wav'\n",
      " b'data/datav2/20_48_00010A.wav']\n",
      "[b'data/datav2/20_50_46100A.wav' b'data/datav2/21_08_08015D.wav'\n",
      " b'data/datav2/20_58_52127C.wav']\n",
      "[b'data/datav2/20_58_52010C.wav' b'data/datav2/21_03_20012D.wav'\n",
      " b'data/datav2/20_58_52190C.wav']\n",
      "[b'data/datav2/20_56_39018B.wav' b'data/datav2/21_08_08005D.wav'\n",
      " b'data/datav2/20_54_21023B.wav']\n",
      "[b'data/datav2/21_03_20007D.wav' b'data/datav2/20_58_52224C.wav'\n",
      " b'data/datav2/20_58_52084C.wav']\n",
      "[b'data/datav2/20_58_52058C.wav' b'data/datav2/20_58_52102C.wav'\n",
      " b'data/datav2/21_03_20002D.wav']\n",
      "[b'data/datav2/20_58_52214C.wav' b'data/datav2/21_03_20003D.wav'\n",
      " b'data/datav2/20_58_52108C.wav']\n",
      "[b'data/datav2/20_58_52200C.wav' b'data/datav2/20_56_39034B.wav'\n",
      " b'data/datav2/21_02_39007D.wav']\n",
      "[b'data/datav2/20_58_52161C.wav' b'data/datav2/20_50_46078A.wav'\n",
      " b'data/datav2/21_03_20006D.wav']\n",
      "[b'data/datav2/21_03_20004D.wav' b'data/datav2/21_02_39003D.wav'\n",
      " b'data/datav2/21_08_08014D.wav']\n",
      "[b'data/datav2/20_58_52124C.wav' b'data/datav2/21_02_39024D.wav'\n",
      " b'data/datav2/20_58_52034C.wav']\n",
      "[b'data/datav2/21_08_08008D.wav' b'data/datav2/20_58_52062C.wav'\n",
      " b'data/datav2/20_58_52154C.wav']\n",
      "[b'data/datav2/20_58_52194C.wav' b'data/datav2/20_58_52030C.wav'\n",
      " b'data/datav2/21_02_39000D.wav']\n",
      "[b'data/datav2/21_02_39018D.wav' b'data/datav2/20_58_52226C.wav'\n",
      " b'data/datav2/21_02_39016D.wav']\n",
      "[b'data/datav2/20_58_52223C.wav' b'data/datav2/20_58_52116C.wav'\n",
      " b'data/datav2/20_58_52076C.wav']\n",
      "[b'data/datav2/21_03_20000D.wav' b'data/datav2/20_58_52222C.wav'\n",
      " b'data/datav2/20_58_52208C.wav']\n",
      "[b'data/datav2/21_02_39001D.wav' b'data/datav2/20_50_46001A.wav'\n",
      " b'data/datav2/20_54_21000B.wav']\n",
      "[b'data/datav2/20_56_39037B.wav' b'data/datav2/20_58_52162C.wav'\n",
      " b'data/datav2/20_58_52098C.wav']\n",
      "[b'data/datav2/20_50_46034A.wav' b'data/datav2/20_58_52231C.wav'\n",
      " b'data/datav2/20_50_46021A.wav']\n",
      "[b'data/datav2/20_58_52121C.wav' b'data/datav2/20_58_52100C.wav'\n",
      " b'data/datav2/20_56_39014B.wav']\n",
      "[b'data/datav2/20_58_52144C.wav' b'data/datav2/20_54_21045B.wav'\n",
      " b'data/datav2/20_58_52219C.wav']\n",
      "[b'data/datav2/20_58_52198C.wav' b'data/datav2/20_54_21010B.wav'\n",
      " b'data/datav2/20_58_52165C.wav']\n",
      "[b'data/datav2/21_08_08009D.wav' b'data/datav2/20_58_52203C.wav'\n",
      " b'data/datav2/21_08_08010D.wav']\n",
      "[b'data/datav2/21_03_20001D.wav' b'data/datav2/20_58_52197C.wav'\n",
      " b'data/datav2/21_02_39009D.wav']\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "UnboundLocalError: local variable 'y' referenced before assignment\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING, DT_INT64], token=\"pyfunc_0\"](arg0)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[<unknown>, <unknown>], output_types=[DT_STRING, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: UnboundLocalError: local variable 'y' referenced before assignment\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING, DT_INT64], token=\"pyfunc_0\"](arg0)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[<unknown>, <unknown>], output_types=[DT_STRING, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5df3cc91d007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: UnboundLocalError: local variable 'y' referenced before assignment\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING, DT_INT64], token=\"pyfunc_0\"](arg0)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[<unknown>, <unknown>], output_types=[DT_STRING, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]"
     ]
    }
   ],
   "source": [
    "logfilepath='data/dataset.txt'\n",
    "dataset = tf.data.TextLineDataset(logfilepath).shuffle(buffer_size=200) #.map(map_function)\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda filename: tuple(tf.py_func(\n",
    "        process_function, [filename],  [tf.string,tf.int64])))\n",
    "\n",
    "dataset=dataset.batch(3)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    for i in range(200):\n",
    "      value = sess.run(next_element[0])\n",
    "      print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "num_steps = 500\n",
    "batch_size = 2\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 128 # MNIST data input (img shape: 28*28)\n",
    "#num_classes = 5 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.int32, [None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 =  tf.nn.relu (tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 =  tf.nn.relu(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "Logits = neural_net(X)\n",
    "\n",
    "Logits = tf.Print(Logits, [Logits,tf.shape(Logits)], message=\"This is a: \")\n",
    "\n",
    "# Define loss and optimizer\n",
    "#loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    " #   logits=logits, labels=Y))\n",
    "prediction = tf.nn.softmax(Logits)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=Logits))\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(Logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "g_1 = tf.Graph()\n",
    "with g_1.as_default():\n",
    "  \n",
    "\n",
    "                \n",
    "                \n",
    "  \n",
    "\n",
    "  # Sessions created in this scope will run operations from `g_1`.\n",
    "                sess1 = tf.Session()\n",
    "        \n",
    "                vggish_slim.define_vggish_slim(training=False)\n",
    "                vggish_slim.load_vggish_slim_checkpoint(sess1, 'vggish_model.ckpt')\n",
    "                features_tensor = sess1.graph.get_tensor_by_name(\n",
    "                vggish_params.INPUT_TENSOR_NAME)\n",
    "                embedding_tensor = sess1.graph.get_tensor_by_name(\n",
    "                vggish_params.OUTPUT_TENSOR_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 96, 64)\n",
      "(2, 128)\n",
      "(2, 128)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must have the same first dimension, got logits shape [2,4] and labels shape [1]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Print, _arg_Placeholder_1_0_1)]]\n\nCaused by op 'SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits', defined at:\n  File \"/home/saurabh/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/saurabh/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-e476081f151b>\", line 12, in <module>\n    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=Logits))\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1964, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 4804, in _sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): logits and labels must have the same first dimension, got logits shape [2,4] and labels shape [1]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Print, _arg_Placeholder_1_0_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must have the same first dimension, got logits shape [2,4] and labels shape [1]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Print, _arg_Placeholder_1_0_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9144116e3cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0;31m# train single example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpostprocessed_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNext_element\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must have the same first dimension, got logits shape [2,4] and labels shape [1]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Print, _arg_Placeholder_1_0_1)]]\n\nCaused by op 'SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits', defined at:\n  File \"/home/saurabh/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/saurabh/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-e476081f151b>\", line 12, in <module>\n    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=Logits))\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1964, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 4804, in _sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): logits and labels must have the same first dimension, got logits shape [2,4] and labels shape [1]\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Print, _arg_Placeholder_1_0_1)]]\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "                sess.run(init)\n",
    "\n",
    "   \n",
    "                sess.run(iterator.initializer)\n",
    "\n",
    "               \n",
    "                \n",
    "                examples_batch = vggish_input.wavfile_to_examples('data/vinay.wav')\n",
    "                print(examples_batch.shape)\n",
    "\n",
    "                # Prepare a postprocessor to munge the model embeddings.\n",
    "                pproc = vggish_postprocess.Postprocessor('vggish_pca_params.npz')\n",
    "                \n",
    "               \n",
    "    # Run inference and postprocessing.\n",
    "                [embedding_batch] = sess1.run([embedding_tensor],\n",
    "                                 feed_dict={features_tensor: examples_batch})\n",
    "                print(embedding_batch.shape)\n",
    "                postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "                print(postprocessed_batch.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "              # train single example\n",
    "                _ , c,l = sess.run([train_op, cost, Logits], feed_dict={X: postprocessed_batch,Y: Next_element[1] })\n",
    "            \n",
    "                 \n",
    "                print(l.shape)\n",
    "                print(c)\n",
    "                #print(pre)\n",
    "      #          print(p)\n",
    "               \n",
    "               \n",
    "              \n",
    "          \n",
    "   \n",
    "        \n",
    "                \n",
    "    # Save model weights to disk\n",
    "   # save_path = saver.save(sess, model_path)\n",
    "    #print(\"Model saved in file: %s\" % save_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/datav2/20_50_46060A.wav\n",
      "(3, 96, 64)\n",
      "(3, 128)\n",
      "(3, 128)\n",
      "(3, 4)\n",
      "316399.66\n",
      "data/datav2/20_50_46047A.wav\n",
      "(3, 96, 64)\n",
      "(3, 128)\n",
      "(3, 128)\n",
      "(3, 4)\n",
      "96877.18\n",
      "data/datav2/20_54_21009B.wav\n",
      "(3, 96, 64)\n",
      "(3, 128)\n",
      "(3, 128)\n",
      "(3, 4)\n",
      "320554.22\n",
      "data/datav2/20_50_46020A.wav\n",
      "(3, 96, 64)\n",
      "(3, 128)\n",
      "(3, 128)\n",
      "(3, 4)\n",
      "0.0\n",
      "data/datav2/20_50_46044A.wav\n",
      "(3, 96, 64)\n",
      "(3, 128)\n",
      "(3, 128)\n",
      "(3, 4)\n",
      "101460.0\n",
      "data/datav2/20_54_21038B.wav\n",
      "(3, 96, 64)\n",
      "(3, 128)\n",
      "(3, 128)\n",
      "(3, 4)\n",
      "204539.73\n",
      "data/datav2/20_50_46066A.wav\n",
      "(3, 96, 64)\n",
      "(3, 128)\n",
      "(3, 128)\n",
      "(3, 4)\n",
      "0.0\n",
      "data/datav2/20_50_46081A.wav\n",
      "(3, 96, 64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9b8fda08111f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Run inference and postprocessing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 [embedding_batch] = sess1.run([embedding_tensor],\n\u001b[0;32m---> 26\u001b[0;31m                                  feed_dict={features_tensor: examples_batch})\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mpostprocessed_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(num_steps):\n",
    "        avg_cost = 0.\n",
    "        \n",
    "        \n",
    "        sess.run(iterator.initializer)\n",
    "        while True:\n",
    "            try:\n",
    "                Next_element=sess.run(next_element)\n",
    "                input_wav_file_name=str(Next_element[0][0],'utf-8')\n",
    "                print(input_wav_file_name)\n",
    "                \n",
    "                examples_batch = vggish_input.wavfile_to_examples(input_wav_file_name)\n",
    "                print(examples_batch.shape)\n",
    "\n",
    "                # Prepare a postprocessor to munge the model embeddings.\n",
    "                pproc = vggish_postprocess.Postprocessor('vggish_pca_params.npz')\n",
    "                \n",
    "               \n",
    "    # Run inference and postprocessing.\n",
    "                [embedding_batch] = sess1.run([embedding_tensor],\n",
    "                                 feed_dict={features_tensor: examples_batch})\n",
    "                print(embedding_batch.shape)\n",
    "                postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "                print(postprocessed_batch.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "              # train single example\n",
    "                _ , c,l = sess.run([train_op, cost, Logits], feed_dict={X: postprocessed_batch,Y: Next_element[1] })\n",
    "            \n",
    "                 \n",
    "                print(l.shape)\n",
    "                print(c)\n",
    "                #print(pre)\n",
    "      #          print(p)\n",
    "               \n",
    "               \n",
    "              \n",
    "            except tf.errors.OutOfRangeError:\n",
    "              break\n",
    "   \n",
    "        \n",
    "                \n",
    "    # Save model weights to disk\n",
    "   # save_path = saver.save(sess, model_path)\n",
    "    #print(\"Model saved in file: %s\" % save_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
